{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebd5aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=885913184552-86iog4pkulojgr4r46vjse61ukaa3ds8.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A59359%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.send+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.modify&state=lwa6v5eXSHzXY6II9nNHnVphMcqln8&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Gmail API scopes for read, send, and modify\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/gmail.readonly',\n",
    "    'https://www.googleapis.com/auth/gmail.send',\n",
    "    'https://www.googleapis.com/auth/gmail.modify'\n",
    "]\n",
    "\n",
    "def authenticate_gmail():\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "# Authenticate and build the Gmail service\n",
    "creds = authenticate_gmail()\n",
    "service = build('gmail', 'v1', credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2234c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email ID: 1992e64cfce773d5\n",
      "Email ID: 1992e3b96bf7c350\n",
      "Email ID: 1992e34587b134ea\n",
      "Email ID: 1992df8114139fb5\n",
      "Email ID: 1992dcf0049d811d\n"
     ]
    }
   ],
   "source": [
    "def get_last_unread_emails(service, max_results=5):\n",
    "    \"\"\"\n",
    "    Fetch the most recent unread emails from the user's inbox.\n",
    "    Returns a list of message dicts, each with an 'id' and 'threadId'.\n",
    "    \"\"\"\n",
    "    query = \"is:unread is:inbox\"\n",
    "    response = service.users().messages().list(\n",
    "        userId='me', q=query, maxResults=max_results\n",
    "    ).execute()\n",
    "    messages = response.get('messages', [])\n",
    "    return messages\n",
    "\n",
    "# Fetch the last 5 unread emails\n",
    "unread_emails = get_last_unread_emails(service, max_results=5)\n",
    "\n",
    "# Example: print the IDs\n",
    "for msg in unread_emails:\n",
    "    print(f\"Email ID: {msg['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96911ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: GTBank Ltd <gtbank@gtbank.com>\n",
      "Subject: Daily FX Rate For International Transactions on Your GTBank Naira Card\n",
      "Date: 09 Sep 2025 12:13:02 -0000\n",
      "---\n",
      "<!DOCTYPE html><html xmlns:v=\"urn:schemas-microsoft-com:vml\" xmlns:o=\"urn:schemas-microsoft-com:office:office\" lang=\"en\"><head><title></title><meta http-equiv=\"Content-Type\" content=\"text/html; charse...\n",
      "========================================\n",
      "From: Akintunde Adedolapo Abigail <invitations@linkedin.com>\n",
      "Subject: You have an invitation\n",
      "Date: Tue, 9 Sep 2025 11:28:01 +0000 (UTC)\n",
      "---\n",
      "Akintunde is waiting for your response\n",
      "        \n",
      "Hi Akintobi, I’d like to join your professional network\n",
      "\n",
      "Akintunde Adedolapo Abigail\n",
      "Administrative Virtual Assistant | Project Management Enthusia...\n",
      "========================================\n",
      "From: OpenAI Developer Community <notifications@openai1.discoursemail.com>\n",
      "Subject: [OpenAI Developer Community] Summary\n",
      "Date: Tue, 09 Sep 2025 11:20:06 +0000\n",
      "---\n",
      "A brief summary of [OpenAI Developer Community][1] since 2025-09-02 11:03:44 UTC\n",
      "\n",
      "66 New Topics\n",
      "1 Unread Notifications\n",
      "5027 New Users\n",
      "\n",
      "\n",
      "  \n",
      "  ### Popular Topics\n",
      "\n",
      "    [PrimeTalk · Inventors of...\n",
      "========================================\n",
      "From: Tangerine life <customerexperience@life.tangerine.africa>\n",
      "Subject: AJIBOLA, Help Us Get Better, For You!\n",
      "Date: Tue, 9 Sep 2025 03:14:08 -0700 (PDT)\n",
      "---\n",
      "\n",
      "\n",
      "This survey is designed to understand any challenge(s) you may face in keeping your policy active — from payments to customer service.\n",
      "With your input, we can address those challenges and support...\n",
      "========================================\n",
      "From: Glassdoor Jobs <noreply@glassdoor.com>\n",
      "Subject: JDE Analyst – EDI ( Remote US) role at RectorSeal: you would be a great fit!\n",
      "Date: Tue, 09 Sep 2025 09:29:24 +0000 (UTC)\n",
      "---\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"><html dir=\"ltr\" lang=\"en\"><head><link rel=\"preload\" as=\"image\" href=\"https://ww...\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "def get_email_data(service, message_id):\n",
    "    msg = service.users().messages().get(userId='me', id=message_id, format='full').execute()\n",
    "    payload = msg['payload']\n",
    "    headers = payload['headers']\n",
    "    email_data = {'id': message_id}\n",
    "\n",
    "    # Extract headers\n",
    "    for header in headers:\n",
    "        name = header['name']\n",
    "        value = header['value']\n",
    "        if name == 'From':\n",
    "            email_data['from'] = value\n",
    "        if name == 'Date':\n",
    "            email_data['date'] = value\n",
    "        if name == 'Subject':\n",
    "            email_data['subject'] = value\n",
    "\n",
    "    # Extract plain text body\n",
    "    body = \"\"\n",
    "    if 'parts' in payload:\n",
    "        for part in payload['parts']:\n",
    "            if part['mimeType'] == 'text/plain':\n",
    "                data = part['body'].get('data')\n",
    "                if data:\n",
    "                    import base64\n",
    "                    body = base64.urlsafe_b64decode(data).decode('utf-8')\n",
    "                    break\n",
    "    else:\n",
    "        data = payload['body'].get('data')\n",
    "        if data:\n",
    "            import base64\n",
    "            body = base64.urlsafe_b64decode(data).decode('utf-8')\n",
    "\n",
    "    email_data['body'] = body\n",
    "    return email_data\n",
    "\n",
    "# Fetch essential info for the last 5 unread emails\n",
    "emails_info = []\n",
    "for msg in unread_emails:\n",
    "    info = get_email_data(service, msg['id'])\n",
    "    emails_info.append(info)\n",
    "    print(f\"From: {info.get('from')}\\nSubject: {info.get('subject')}\\nDate: {info.get('date')}\\n---\\n{info.get('body')[:200]}...\\n{'='*40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c7c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from beautifulsoup4) (4.14.0)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "\n",
      "   ---------------------------------------- 0/2 [soupsieve]\n",
      "   ---------------------------------------- 0/2 [soupsieve]\n",
      "   ---------------------------------------- 0/2 [soupsieve]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   ---------------------------------------- 2/2 [beautifulsoup4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.13.4 soupsieve-2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22c0d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_hyperlinks(text):\n",
    "    # Simple function to remove hyperlinks from text\n",
    "    import re\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def get_email_data(service, message_id):\n",
    "    msg = service.users().messages().get(userId='me', id=message_id, format='full').execute()\n",
    "    payload = msg['payload']\n",
    "    headers = payload['headers']\n",
    "    email_data = {'id': message_id}\n",
    "\n",
    "    # Extract headers\n",
    "    for header in headers:\n",
    "        name = header['name']\n",
    "        value = header['value']\n",
    "        if name == 'From':\n",
    "            email_data['from'] = value\n",
    "        if name == 'Date':\n",
    "            email_data['date'] = value\n",
    "        if name == 'Subject':\n",
    "            email_data['subject'] = value\n",
    "\n",
    "    # Extract text content, prefer plain text, fallback to HTML\n",
    "    data = None\n",
    "    text = \"\"\n",
    "    if 'parts' in payload:\n",
    "        for part in payload['parts']:\n",
    "            if part['mimeType'] == 'text/plain' and part['body'].get('data'):\n",
    "                data = part['body']['data']\n",
    "                break\n",
    "        if not data:\n",
    "            for part in payload['parts']:\n",
    "                if part['mimeType'] == 'text/html' and part['body'].get('data'):\n",
    "                    data = part['body']['data']\n",
    "                    break\n",
    "    else:\n",
    "        data = payload['body'].get('data')\n",
    "\n",
    "    if data:\n",
    "        text = base64.urlsafe_b64decode(data.encode('UTF-8')).decode('UTF-8')\n",
    "        # If HTML, clean it\n",
    "        soup = BeautifulSoup(text, 'html.parser')\n",
    "        clean_text = soup.get_text()\n",
    "        clean_text = remove_hyperlinks(clean_text)\n",
    "        email_data['text'] = clean_text.strip()\n",
    "    else:\n",
    "        email_data['text'] = \"\"\n",
    "\n",
    "    return email_data\n",
    "\n",
    "# Usage example:\n",
    "# email_data = get_email_data(service, message['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c736b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (1.86.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\admin agent\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "689d1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb99b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: GTBank Ltd <gtbank@gtbank.com>\n",
      "Subject: Daily FX Rate For International Transactions on Your GTBank Naira Card\n",
      "Timestamp: 09 Sep 2025 12:13:02 -0000\n",
      "Link: https://mail.google.com/mail/u/0/#inbox/1992e64cfce773d5\n",
      "Summary:\n",
      "The email promotes a payment service for purchasing favorite items and offers an option to unsubscribe from receiving further emails.\n",
      "\n",
      "- Payment service for all purchases\n",
      "- Easy way to pay for favorite items\n",
      "- Unsubscribe option available\n",
      "\n",
      "\n",
      "From: Akintunde Adedolapo Abigail <invitations@linkedin.com>\n",
      "Subject: You have an invitation\n",
      "Timestamp: Tue, 9 Sep 2025 11:28:01 +0000 (UTC)\n",
      "Link: https://mail.google.com/mail/u/0/#inbox/1992e3b96bf7c350\n",
      "Summary:\n",
      "Akintobi received a LinkedIn invitation from Akintunde seeking to connect professionally.\n",
      "- Akintunde is an Administrative Virtual Assistant interested in project management and client relationships.\n",
      "- They have 4 common connections in Lagos.\n",
      "- LinkedIn suggests using Premium InMail for better communication effectiveness.\n",
      "\n",
      "\n",
      "From: OpenAI Developer Community <notifications@openai1.discoursemail.com>\n",
      "Subject: [OpenAI Developer Community] Summary\n",
      "Timestamp: Tue, 09 Sep 2025 11:20:06 +0000\n",
      "Link: https://mail.google.com/mail/u/0/#inbox/1992e34587b134ea\n",
      "Summary:\n",
      "The email provides updates from the OpenAI Developer Community as of 2025-09-02, discussing various topics and user activity. It also delves into strategies to reduce AI hallucinations and an issue with GPT-5's language responses. Furthermore, it addresses concerns about the retirement of Standard Voice and the lack of support for custom GPT actions, leading to user dissatisfaction.\n",
      "\n",
      "- 66 new topics posted; 1 unread notification; 5027 new users welcomed.\n",
      "- Popular topics: Lyra Prompt introduction in PrimeTalk; concerns about Standard Voice retirement affecting Pro users' workflows.\n",
      "- Ways to reduce AI hallucinations, with a suggestion to let models skip unknown questions.\n",
      "- Specific issue with GPT-5 responding in German instead of the intended language, prompting discussions on enforcing language response reliably.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "import openai\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/gmail.readonly',\n",
    "    'https://www.googleapis.com/auth/gmail.send',\n",
    "    'https://www.googleapis.com/auth/gmail.modify'\n",
    "]\n",
    "\n",
    "# --- AUTHENTICATION ---\n",
    "def authenticate_gmail():\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "creds = authenticate_gmail()\n",
    "service = build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "def remove_hyperlinks(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'\\S+\\.com\\S*', '', text)\n",
    "    text = re.sub(r'\\S+\\.net\\S*', '', text)\n",
    "    text = re.sub(r'\\S+\\.org\\S*', '', text)\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, max_chars):\n",
    "    paragraphs = re.split(r'\\n+', text)\n",
    "    chunks, current_chunk = [], ''\n",
    "    for paragraph in paragraphs:\n",
    "        if len(current_chunk) + len(paragraph) <= max_chars:\n",
    "            current_chunk += paragraph + '\\n'\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = paragraph + '\\n'\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return [c for c in chunks if c.strip()]\n",
    "\n",
    "# --- EMAIL FETCHING AND CLEANING ---\n",
    "def get_email_data(service, message_id):\n",
    "    message = service.users().messages().get(userId='me', id=message_id, format='full').execute()\n",
    "    payload = message['payload']\n",
    "    headers = payload['headers']\n",
    "    email_data = {\n",
    "        'subject': next((h['value'] for h in headers if h['name'] == 'Subject'), ''),\n",
    "        'from': next((h['value'] for h in headers if h['name'] == 'From'), ''),\n",
    "        'date': next((h['value'] for h in headers if h['name'] == 'Date'), '')\n",
    "    }\n",
    "    data = None\n",
    "    if 'parts' in payload:\n",
    "        for part in payload['parts']:\n",
    "            if part['mimeType'] == 'text/plain' and part['body'].get('data'):\n",
    "                data = part['body']['data']\n",
    "                break\n",
    "        if not data:\n",
    "            for part in payload['parts']:\n",
    "                if part['mimeType'] == 'text/html' and part['body'].get('data'):\n",
    "                    data = part['body']['data']\n",
    "                    break\n",
    "    else:\n",
    "        data = payload['body'].get('data')\n",
    "    if data:\n",
    "        decoded = base64.urlsafe_b64decode(data.encode('UTF-8')).decode('UTF-8')\n",
    "        soup = BeautifulSoup(decoded, 'html.parser')\n",
    "        clean_text = remove_hyperlinks(soup.get_text())\n",
    "        email_data['text'] = clean_text\n",
    "    else:\n",
    "        email_data['text'] = ''\n",
    "    return email_data, message\n",
    "\n",
    "# --- SUMMARIZATION ---\n",
    "def summarize_email(email_text, model=\"gpt-3.5-turbo\"):\n",
    "    system_prompt = (\n",
    "        \"You are a professional email summarizer that creates hybrid summaries. \"\n",
    "        \"Use a short narrative paragraph to introduce or explain the context, \"\n",
    "        \"then follow up with 2–4 bullet points for specific details. \"\n",
    "        \"Avoid repeating information. Keep it under 120 words.\"\n",
    "    )\n",
    "\n",
    "    user_input = f\"Summarize this email with a hybrid style: {email_text}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0.8,\n",
    "                top_p=1,\n",
    "                presence_penalty=0.4,\n",
    "                frequency_penalty=0.3\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"OpenAI error: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return \"Summary could not be generated due to an error.\"\n",
    "\n",
    "# --- MAIN LOGIC TO PROCESS UNREAD EMAILS ---\n",
    "def process_unread_emails(service, max_chars=3000, max_results=3):\n",
    "    results = service.users().messages().list(userId='me', labelIds=['INBOX', 'UNREAD'], maxResults=max_results).execute()\n",
    "    messages = results.get('messages', [])\n",
    "    email_summaries = \"\"\n",
    "    for message in messages:\n",
    "        email_data, full_message = get_email_data(service, message['id'])\n",
    "        text = email_data.get('text', '')\n",
    "        if not text.strip():\n",
    "            continue\n",
    "        chunks = chunk_text(text, max_chars)\n",
    "        summary = \"\"\n",
    "        for chunk in chunks:\n",
    "            if not chunk.strip():\n",
    "                continue\n",
    "            summary += summarize_email(chunk) + \"\\n\"\n",
    "        # Optional: Refine summary if too long (limit to 2 refinements)\n",
    "        refine_attempts = 0\n",
    "        while len(summary.split()) >= 125 and refine_attempts < 2:\n",
    "            summary = summarize_email(summary)\n",
    "            refine_attempts += 1\n",
    "        email_summaries += (\n",
    "            f\"From: {email_data['from']}\\n\"\n",
    "            f\"Subject: {email_data['subject']}\\n\"\n",
    "            f\"Timestamp: {email_data['date']}\\n\"\n",
    "            f\"Link: https://mail.google.com/mail/u/0/#inbox/{message['id']}\\n\"\n",
    "            f\"Summary:\\n{summary}\\n\\n\"\n",
    "        )\n",
    "    return email_summaries\n",
    "\n",
    "# --- RUN ---\n",
    "summaries = process_unread_emails(service)\n",
    "print(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6dd5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
